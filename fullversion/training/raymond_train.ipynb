{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raymond LoRA 训练 - Full Version\n",
    "\n",
    "**运行前检查：**\n",
    "- Runtime → Change runtime type → 选择 H100/A100/T4\n",
    "- 已挂载 Google Drive，raymond_train.json 放在 Drive 的 raymond/ 文件夹\n",
    "\n",
    "| 参数 | T4 | A100 | H100 |\n",
    "|---|---|---|---|\n",
    "| lora_rank | 32 | 32 | 64 |\n",
    "| batch_size | 2 | 4 | 8 |\n",
    "| learning_rate | 1e-4 | 1e-4 | 5e-5 |\n",
    "| 量化 | 4bit | 无 | 无 |\n",
    "| 预计时长 | ~60分钟 | ~20分钟 | ~8分钟 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1：安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q llamafactory\n",
    "!llamafactory-cli version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 登录 HuggingFace（下载 Qwen3-4B 需要）\n",
    "# 去 https://huggingface.co/settings/tokens 生成一个 Read token\n",
    "from huggingface_hub import login\n",
    "login()  # 会弹出输入框，粘贴你的 HF token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2：挂载 Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "import os, json\n",
    "DATA_PATH = \"/content/drive/MyDrive/raymond/raymond_train.json\"\n",
    "assert os.path.exists(DATA_PATH), f\"找不到: {DATA_PATH}\"\n",
    "with open(DATA_PATH) as f:\n",
    "    data = json.load(f)\n",
    "print(f\"训练样本数: {len(data)} 条\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3：准备数据目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, shutil\n",
    "\n",
    "DATA_DIR = \"/content/llama_factory_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "DATA_PATH = \"/content/drive/MyDrive/raymond/raymond_train.json\"\n",
    "shutil.copy(DATA_PATH, f\"{DATA_DIR}/raymond_train.json\")\n",
    "\n",
    "dataset_info = {\n",
    "    \"raymond_full\": {\n",
    "        \"file_name\": \"raymond_train.json\",\n",
    "        \"formatting\": \"sharegpt\",\n",
    "        \"columns\": {\"messages\": \"conversations\"},\n",
    "        \"tags\": {\n",
    "            \"role_tag\": \"from\",\n",
    "            \"content_tag\": \"value\",\n",
    "            \"user_tag\": \"human\",\n",
    "            \"assistant_tag\": \"gpt\",\n",
    "            \"system_tag\": \"system\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "with open(f\"{DATA_DIR}/dataset_info.json\", \"w\") as f:\n",
    "    json.dump(dataset_info, f, indent=2)\n",
    "print(\"准备完成:\", os.listdir(DATA_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4：检查 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    name = torch.cuda.get_device_name(0)\n",
    "    mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"GPU: {name}\")\n",
    "    print(f\"显存: {mem:.1f} GB\")\n",
    "    if mem >= 70:\n",
    "        print(\"→ H100 模式\")\n",
    "    elif mem >= 35:\n",
    "        print(\"→ A100 模式\")\n",
    "    else:\n",
    "        print(\"→ T4 模式\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5：生成训练配置并开始训练\n",
    "\n",
    "脚本会根据显存自动选择最优参数，无需手动改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, yaml, os\n",
    "\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/raymond/train_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "mem_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "\n",
    "if mem_gb >= 70:  # H100\n",
    "    quant_config = {}\n",
    "    batch_size = 8\n",
    "    grad_accum = 2\n",
    "    lora_rank = 64\n",
    "    lora_alpha = 128\n",
    "    learning_rate = 5e-5\n",
    "    print(f\"H100 模式: bf16 全精度\")\n",
    "elif mem_gb >= 35:  # A100\n",
    "    quant_config = {}\n",
    "    batch_size = 4\n",
    "    grad_accum = 4\n",
    "    lora_rank = 32\n",
    "    lora_alpha = 64\n",
    "    learning_rate = 1e-4\n",
    "    print(f\"A100 模式: bf16 全精度\")\n",
    "else:  # T4\n",
    "    quant_config = {\n",
    "        \"quantization_bit\": 4,\n",
    "        \"quantization_method\": \"bnb\",\n",
    "        \"double_quantization\": True,\n",
    "    }\n",
    "    batch_size = 2\n",
    "    grad_accum = 8\n",
    "    lora_rank = 32\n",
    "    lora_alpha = 64\n",
    "    learning_rate = 1e-4\n",
    "    print(f\"T4 模式: 4bit 量化\")\n",
    "\n",
    "train_config = {\n",
    "    \"model_name_or_path\": \"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "    \"template\": \"qwen3_nothink\",\n",
    "    \"trust_remote_code\": True,\n",
    "    \"flash_attn\": \"auto\",\n",
    "    \"dataset\": \"raymond_full\",\n",
    "    \"dataset_dir\": \"/content/llama_factory_data\",\n",
    "    \"cutoff_len\": 2048,\n",
    "    \"max_samples\": 100000,\n",
    "    \"preprocessing_num_workers\": 4,\n",
    "    \"stage\": \"sft\",\n",
    "    \"do_train\": True,\n",
    "    \"finetuning_type\": \"lora\",\n",
    "    \"lora_rank\": lora_rank,\n",
    "    \"lora_alpha\": lora_alpha,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"lora_target\": \"all\",\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"per_device_train_batch_size\": batch_size,\n",
    "    \"gradient_accumulation_steps\": grad_accum,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"warmup_steps\": 50,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"optim\": \"adamw_torch\",\n",
    "    \"bf16\": True,\n",
    "    \"output_dir\": OUTPUT_DIR,\n",
    "    \"logging_steps\": 10,\n",
    "    \"save_steps\": 100,\n",
    "    \"plot_loss\": True,\n",
    "    \"report_to\": \"none\",\n",
    "    **quant_config,\n",
    "}\n",
    "\n",
    "config_path = \"/content/raymond_train_config.yaml\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    yaml.dump(train_config, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(f\"lora_rank={lora_rank}, lora_alpha={lora_alpha}\")\n",
    "print(f\"等效 batch size: {batch_size * grad_accum}\")\n",
    "print(f\"learning_rate: {learning_rate}\")\n",
    "print(\"配置已生成，开始训练...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!llamafactory-cli train /content/raymond_train_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6：验证训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/raymond/train_output\"\n",
    "print(\"输出文件:\", os.listdir(OUTPUT_DIR))\n",
    "\n",
    "results_path = f\"{OUTPUT_DIR}/all_results.json\"\n",
    "if os.path.exists(results_path):\n",
    "    with open(results_path) as f:\n",
    "        results = json.load(f)\n",
    "    loss = results.get(\"train_loss\", 999)\n",
    "    print(f\"最终 loss: {loss:.4f}\")\n",
    "    print(f\"训练时长: {results.get('train_runtime', 0)/60:.1f} 分钟\")\n",
    "    if loss < 0.8:\n",
    "        print(\"loss 良好\")\n",
    "    elif loss < 1.2:\n",
    "        print(\"loss 一般，效果可接受\")\n",
    "    else:\n",
    "        print(\"loss 偏高，可能需要调参\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7：快速测试模型效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/raymond/train_output\"\n",
    "BASE_MODEL = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "print(\"加载模型...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL, torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\", trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(base, OUTPUT_DIR)\n",
    "model.eval()\n",
    "print(\"模型加载完成\")\n",
    "\n",
    "SYSTEM = \"你是Raymond，一个在美国宾夕法尼亚留学的中国研究生，计算机专业，本科国内双非。你说话短而碎，喜欢连发多条短消息，像微信聊天一样。你常用的口头禅有66、哈、f、说白了、不好说、俺、无敌了、我真谢了。你的幽默方式是自嘲和反讽，表面毒舌但实际很关心朋友。\"\n",
    "\n",
    "def chat(user_input):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=True, add_generation_prompt=True,\n",
    "        return_tensors=\"pt\", return_dict=True\n",
    "    )\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs, max_new_tokens=200,\n",
    "            temperature=0.8, do_sample=True, top_p=0.9\n",
    "        )\n",
    "    prompt_len = inputs[\"input_ids\"].shape[-1]\n",
    "    return tokenizer.decode(out[0][prompt_len:], skip_special_tokens=True)\n",
    "\n",
    "for q in [\"你在干嘛\", \"今天吃什么\", \"铲吗\", \"你后悔出国吗\"]:\n",
    "    print(f\"朋友: {q}\")\n",
    "    print(f\"Raymond: {chat(q)}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8（训练完成后运行）：合并 LoRA 为完整模型\n",
    "\n",
    "合并后导入 Ollama，Step 4 再运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MERGED_DIR = \"/content/drive/MyDrive/raymond/merged_model\"\n",
    "os.makedirs(MERGED_DIR, exist_ok=True)\n",
    "\n",
    "print(\"合并 LoRA adapter...\")\n",
    "merged = model.merge_and_unload()\n",
    "merged.save_pretrained(MERGED_DIR)\n",
    "tokenizer.save_pretrained(MERGED_DIR)\n",
    "print(f\"合并完成: {MERGED_DIR}\")\n",
    "print(os.listdir(MERGED_DIR))"
   ]
  }
 ]
}